{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e00631ab-71b1-4ad5-a654-751b3746fffd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Enterprise Fleet Analytics Pipeline: Focuses on the business outcome (analytics) and the domain (fleet/logistics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afa843b9-d18d-4b6a-b92c-ab6eb2afe667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](./logistics_project.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c1e3853-7e94-4e81-a743-bb302ff55ad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##**1. Data Munging** -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10677f57-f424-40d9-90a3-bcf94ec9c1a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####1. Visibily/Manually opening the file and capture couple of data patterns (Manual Exploratory Data Analysis)\n",
    "\n",
    "**Source 1: Logistics Shipment Data (JSON Format)**\n",
    "- Data is received from the source system in JSON[Semi strcutured format]\n",
    "- key–value pairs\n",
    "\n",
    "**Source 2: Logistics Data (CSV Format – 4 Columns)**\n",
    "- Data is received in CSV format with 4 columns\n",
    "- Header present, no footer\n",
    "- Null columns and null records are there\n",
    "- Data format inconsistencies observed like age contain string value\n",
    "- Includes additional column(s)\n",
    "\n",
    "**Source 3: Logistics Data (CSV Format – 7 Columns)**\n",
    "- Data is received in CSV format with 7 columns\n",
    "- Header present, no footer\n",
    "- Contains duplicate records\n",
    "- Null columns and null records are there\n",
    "- Data format inconsistencies observed like age contain string value\n",
    "- Includes additional column(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "381c25cd-503d-4662-8935-611381f53535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####2. Programatically try to find couple of data patterns applying below EDA (File: logistics_source1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "440d7677-d3dc-4053-99ee-ae0de28ebc84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Apply inferSchema and toDF to create a DF and analyse the actual data.\n",
    "2. Analyse the schema, datatypes, columns etc.,\n",
    "3. Analyse the duplicate records count and summary of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64ad2f93-eff6-4706-b3fd-0552962f5f80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source1_df=spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/logistics_data_analysis/Silver_data/logistics_source1\",header=True).toDF(\"Shipment_id\",\"First_Name\",\"Last_Name\",\"Age\",\"Role\")\n",
    "\n",
    "display(source1_df.show(10,False))\n",
    "display(source1_df.columns)\n",
    "display(source1_df.dtypes) #Age is in string format and shippment ID is in string type\n",
    "print(\"Raw data in the source1 DF:\",source1_df.count())\n",
    "print(\"Non Duplicate records:\",source1_df.distinct().count())\n",
    "\n",
    "\n",
    "source2_df=spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/logistics_data_analysis/Silver_data/logistics_source2\",header=True)\n",
    "display(source2_df.show(10,False))\n",
    "display(source2_df.columns)\n",
    "display(source2_df.dtypes) #Age is in string format and shippment ID is in string type\n",
    "print(\"Raw data in the source2 DF:\",source2_df.count())\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "logistics_data_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
