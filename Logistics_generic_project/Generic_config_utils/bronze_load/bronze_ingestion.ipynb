{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b3ff3f-b13d-4372-9761-0a64d916bde5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Enterprise Fleet Analytics Pipeline: Focuses on the business outcome (analytics) and the domain (fleet/logistics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2423d59c-1bc4-4a9c-8e06-99f1e6c601fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog\",\"\")\n",
    "CATALOG=dbutils.widgets.get(\"catalog\").strip()\n",
    "dbutils.widgets.text(\"schema\",\"\")\n",
    "SCHEMA=dbutils.widgets.get(\"schema\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725603eb-4fff-4417-a925-70be372d6165",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#As we are parameterizing, we don't need to hardcode, which is not production ready..\n",
    "#CATALOG='prodcatalog'\n",
    "#SCHEMA='logistics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a8fc33e-7116-4eb6-82a4-6c2656a46d11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Setting generic configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df536798-932a-4aab-a2d1-6785b81bb8f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#IMPORTANT DATABRICKS INTERVIEW QUESITON: When I run a notebook using dbutils.notebook.run(notebook,maxrunseconds,paramerters as dictionary)\n",
    "#1. It will run the notebook in the respective folder/instance/autonomously (hence we don't get in the parent notebook, all the variables/values set in the child notebook). If we use %run, the child notebook variable/values can be accessed in the parent notebook directly because it runs inline/within the parent notebook scope.\n",
    "#2. Using dbutils.notebook.run(notebook,maxrunseconds,paramerters as dictionary) - we can pass parameters to the child notebook, but %run will not allow us to pass params\n",
    "\n",
    "config_nb_output = dbutils.notebook.run(\n",
    "    \"/Workspace/Users/sunilasha625@gmail.com/DataBricksCodeRepo/Logistics_generic_project/Generic_config_utils/general_fun_config_utils/config_catalog_schema_table\",\n",
    "    120,{\"catalog\": CATALOG,\"schema\": SCHEMA})\n",
    "\n",
    "#print(SRC) #this will throw error\n",
    "\n",
    "config_dict = json.loads(config_nb_output)\n",
    "print(config_dict)\n",
    "\n",
    "#CATALOG = config_dict[\"CATALOG\"]\n",
    "#SCHEMA = config_dict[\"SCHEMA\"]\n",
    "SRC=config_dict[\"SRC\"]\n",
    "BRONZE = config_dict[\"BRONZE\"]\n",
    "#SILVER = config_dict[\"SILVER\"]\n",
    "#GOLD = config_dict[\"GOLD\"]\n",
    "#SILVERDB = config_dict[\"SILVERDB\"]\n",
    "#GOLDDB = config_dict[\"GOLDDB\"]\n",
    "\n",
    "print(\"returned source location is \",SRC)\n",
    "print(\"returned target bronze location is \",BRONZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b41758e-9d55-43c3-84dc-bde2f71715c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f443aeb6-1942-4828-ab38-8860f93bdcef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/sunilasha625@gmail.com/DataBricksCodeRepo/Logistics_generic_project/Generic_config_utils/general_fun_config_utils/genric_utils_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4469fff4-1908-4d20-ad46-891a087a500c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Starting the Bronze layer execution - Read data from source (SRC) datalake and load into target datalake (bronze volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da9cd381-227a-4121-b2e8-e2fadee17b0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Adapting Generic Framework\n",
    "spark=get_spark_session(\"Logistics Data Engineering Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac710769-cea3-4caa-a747-478f7927bee5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#No Adoption of Generic Framework (Inline programming)\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Logistics Data Engineering Project\").getOrCreate()\n",
    "'''\n",
    "We lost all the below features...\n",
    "    Centralized and controllable\n",
    "    Production Ready\n",
    "    Reusability\n",
    "    Seperation of Concern\n",
    "    Modularized\n",
    "    Simple to write/Reasonable to understand\n",
    "    Optimization\n",
    "    Governed\n",
    "    Secured\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bbaaf5e-b875-4d4d-a669-0e764b6230a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#All Read ops\n",
    "#Staff data read operations\n",
    "#inline coding\n",
    "#staff1=spark.read.csv(f\"{SRC}/logistics_source1.txt\",header=True,inferSchema=True)\n",
    "#inline functions\n",
    "#def fun1():\n",
    "#    return spark.read.csv(f\"{SRC}/logistics_source2.txt\",header=True,inferSchema=True)\n",
    "\n",
    "#or better prod standard approach is calling the generic framework\n",
    "staff1=read_file(spark,'csv',f\"{SRC}/logistics_source1.txt\",True,False)\n",
    "#inline\n",
    "staff2=read_csv_df(spark,f\"{SRC}/logistics_source2.txt\",True,False)\n",
    "#print(staff1.schema)\n",
    "#print(staff2.schema)\n",
    "\n",
    "#staff_bronze_same_structure=unionDf(staff1,staff2)#Needed if the EDA output says both data sources have same structure\n",
    "#staff_bronze_same_structure=staff1.union(staff2)\n",
    "\n",
    "\n",
    "staff_bronze=mergeDf(staff1,staff2) #Needed if the EDA output says both data sources have different structure\n",
    "\n",
    "\n",
    "#Geo tagging data read operations\n",
    "geo_tagging=read_csv_df(spark,f\"{SRC}/Master_City_List.csv\",True,False)\n",
    "\n",
    "#Shipment data read operations\n",
    "shipments_bronze = read_json_df(spark,f\"{SRC}/logistics_shipment_detail_3000.json\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c82fe802-ec5b-4e61-8f12-1ad93b1e8fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#All Read ops from Source Datalake/any other sources\n",
    "#Staff data read operations\n",
    "staff1=read_file(spark,'csv',f\"{SRC}/logistics_source1.txt\",True,False)\n",
    "staff2=read_csv_df(spark,f\"{SRC}/logistics_source2.txt\",True,False)\n",
    "staff_bronze=mergeDf(staff1,staff2)\n",
    "geo_tagging=read_csv_df(spark,f\"{SRC}/Master_City_List.csv\",True,False)\n",
    "shipments_bronze = read_json_df(spark,f\"{SRC}/logistics_shipment_detail_3000.json\",True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingestion",
   "widgets": {
    "catalog": {
     "currentValue": "logistic",
     "nuid": "79f104f8-ae90-405c-9cae-e20b19b38c5e",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "logisticschema",
     "nuid": "472ec53c-2422-454c-a5c0-93ea238d284b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
