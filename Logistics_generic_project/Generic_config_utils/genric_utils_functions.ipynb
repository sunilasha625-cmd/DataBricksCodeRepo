{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "135fbf09-93eb-484f-bb81-d1f9596fa7c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Running Utility Notebook to initialize all functions to use further\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c9fd7b-5dcd-4e37-a790-43572595c708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install word2number\n",
    "#print(w2n.word_to_num(\"two hundred and thirty five\")) ---->235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "695610b8-651c-4d96-b27e-6d9c65d3d46e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from word2number import w2n\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def word_to_num(value):\n",
    "    try:\n",
    "        #if already numeric\n",
    "        return int(value)\n",
    "    except:\n",
    "        try:\n",
    "            return w2n.word_to_num(value.lower())\n",
    "        except:\n",
    "            return None\n",
    "#Register this Python function and tell Spark what type it will return\n",
    "#udf(function, returnType)\n",
    "word_to_num_udf=udf(word_to_num,IntegerType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5923216c-90e6-45fb-bad6-7bb64ee8bc8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Inline/Business Specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e0a09a-4c24-48e8-af4b-7d50299734b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def standardize_staff(df):\n",
    "    return (\n",
    "        df.withColumn(\"shipment_id\",word_to_num_udf(col(\"shipment_id\")).cast(\"long\"))\n",
    "        .withColumn(\"age\",word_to_num_udf(col(\"age\")).cast(\"int\"))\n",
    "        .withColumn(\"role\",f.lower(\"role\"))\n",
    "        .withColumn(\"origin_hub_city\",f.initcap(col(\"origin_hub_city\")))\n",
    "        .withColumn(\"load_dt\",f.current_timestamp())\n",
    "        .withColumn(\"full_name\",f.concat_ws(\" \",\"first_name\",\"last_name\"))\n",
    "        .withColumn(\"hub_location\",f.initcap(\"hub_location\"))\n",
    "        .drop(\"first_name\",\"last_name\")\n",
    "        .withColumnRenamed(\"full_name\",\"staff_full_name\")\n",
    "    )\n",
    "\n",
    "def scrub_geotag(df):\n",
    "    return(\n",
    "        df.withColumn(\"city_name\",f.initcap(\"city_name\"))\n",
    "        .withColumn(\"masked_hub_location\",f.initcap(\"masked_hub_location\"))\n",
    "    )\n",
    "\n",
    "def standardize_shipments(df):\n",
    "    return(\n",
    "        df\n",
    "        .withColumn(\"domain\", F.lit(\"Logistics\"))\n",
    "        .withColumn(\"ingestion_timestamp\", F.current_timestamp())\n",
    "        .withColumn(\"is_expedited\", F.lit(False).cast(\"boolean\"))\n",
    "        .withColumn(\"shipment_date\", F.to_date(\"shipment_date\", \"yy-MM-dd\"))\n",
    "        .withColumn(\"shipment_cost\", F.round(\"shipment_cost\", 2))\n",
    "        .withColumn(\"shipment_weight_kg\", F.col(\"shipment_weight_kg\").cast(\"double\"))\n",
    "    )\n",
    "\n",
    "def enrich_shipments(df):\n",
    "    return(\n",
    "        df.withCoulmn(\"route_segment\",f.concat_ws(\"-\",\"source_city\",\"destination_city\"))\n",
    "        .withColumn(\"vehicle_identifier\",f.concat_ws(\"_\",\"vehicle_type\", \"shipment_id\"))\n",
    "        .withColumn(\"shipment_year\",f.year(\"shipment_year\"))\n",
    "        .withColumn(\"shipment_year\",f.month(\"shipment_year\"))\n",
    "        .withColumn(\"is_weekend\",f.dayofweek(\"shipment_date\").isin([1,7]))\n",
    "        .withColumn(\"is_expedited\",f.col(\"shipment_status\").isin(\"IN_TRANSIT\",\"DELIVERED\"))\n",
    "        .withColumn(\"cost_per_kg\",\n",
    "        f.round(F.col(\"shipment_cost\") / F.col(\"shipment_weight_kg\"), 2))\n",
    "        .withColumn(\"tax_amount\",\n",
    "        f.round(F.col(\"shipment_cost\") * 0.18, 2))\n",
    "        .withColumn(\"days_since_shipment\",\n",
    "        f.datediff(F.current_date(), \"shipment_date\"))\n",
    "        .withColumn(\"is_high_value\",\n",
    "        f.col(\"shipment_cost\") > 50000)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "genric_utils_functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
