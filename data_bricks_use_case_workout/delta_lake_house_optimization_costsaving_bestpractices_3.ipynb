{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd02a1ea-bc27-4ac4-a04a-f9af57f89698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Data Skew**\n",
    "Data skew means data is unevenly distributed, causing some tasks to do much more work than others.\n",
    "\n",
    "Imagine 4 people carrying boxes:\n",
    "\n",
    "Person 1 ‚Üí 1 box<br>\n",
    "Person 2 ‚Üí 1 box<br>\n",
    "Person 3 ‚Üí 1 box<br>\n",
    "Person 4 ‚Üí 100 boxes üòì<br>\n",
    "\n",
    "Everyone must wait for Person 4 to finish.<br>\n",
    "\n",
    "üëâ That imbalance is data skew.<br>\n",
    "\n",
    "Data Skew in Spark (Very Simple)\n",
    "\n",
    "Spark splits data into partitions.<br>\n",
    "Each partition is processed by one task.<br>\n",
    "\n",
    "**Ideal case**\n",
    "\n",
    "Partition 1 ‚Üí 1M rows<br>\n",
    "Partition 2 ‚Üí 1M rows<br>\n",
    "Partition 3 ‚Üí 1M rows<br>\n",
    "Partition 4 ‚Üí 1M rows<br>\n",
    "All tasks finish together ‚úÖ<br>\n",
    "\n",
    "**Skewed case**\n",
    "Partition 1 ‚Üí 50 rows<br>\n",
    "Partition 2 ‚Üí 70 rows<br>\n",
    "Partition 3 ‚Üí 80 rows<br>\n",
    "Partition 4 ‚Üí 10M rows üò±<br>\n",
    "\n",
    "3 tasks finish quickly<br>\n",
    "1 task runs forever<br>\n",
    "\n",
    "üëâ Job is slow ‚Üí data skew<br>\n",
    "\n",
    "Why Data Skew Happens<br>\n",
    "1Ô∏è‚É£ Skewed values in a column<br>\n",
    "Example:<br>\n",
    "country = 'IN' ‚Üí 90% of rows<br>\n",
    "country = others ‚Üí 10%<br>\n",
    "Partitioning or grouping by country causes skew.<br>\n",
    "\n",
    "1Ô∏è‚É£ JOIN Skew (Most Common)\n",
    "‚ùå Problem\n",
    "\n",
    "Joining on a skewed key<br>\n",
    "Example:<br>\n",
    "\n",
    "SELECT *<br>\n",
    "FROM orders o<br>\n",
    "JOIN customers c<br>\n",
    "ON o.country = c.country;<br>\n",
    "Data:<br>\n",
    "\n",
    "country = 'IN' ‚Üí 90% of rows<br>\n",
    "\n",
    "‚ö†Ô∏è Why Skew Happens<br>\n",
    "All IN rows go to one shuffle partition<br>\n",
    "One task becomes huge<br>\n",
    "Job waits for that task<br>\n",
    "\n",
    "‚úÖ Solutions<br>\n",
    "‚úÖ Best: Broadcast JOIN (if one table is small)<br>\n",
    "\n",
    "SELECT /*+ BROADCAST(customers) */ *<Br>\n",
    "FROM orders o<br>\n",
    "JOIN customers c<br>\n",
    "ON o.country = c.country;<br>\n",
    "\n",
    "Rows with the same join key must be processed by the same task.<br>\n",
    "Otherwise Spark could not match orders.IN with customers.IN.<br>\n",
    "Before the join, Spark performs a shuffle on both tables.<br>\n",
    "\n",
    "Each row is sent to a partition based on:<br>\n",
    "partition_id = hash(join_key) % num_shuffle_partitions<br>\n",
    "here join_key = country<br>\n",
    "\n",
    "Why All 'IN' Rows Go Together<br>\n",
    "country = 'IN' ‚Üí 90% of rows<br>\n",
    "Important fact:<br>\n",
    "hash(\"IN\") is always the same<br>\n",
    "Hashing is deterministic<br>\n",
    "So for every row:\n",
    "hash(\"IN\") % N  ‚Üí same partition number<br>\n",
    "üëâ Spark must do this to make the join correct.<br>\n",
    "\n",
    "**Visualizing the Shuffle**\n",
    "\n",
    "Imagine spark.sql.shuffle.partitions = 4<br>\n",
    "| Country | hash(country) % 4 | Partition       |\n",
    "| ------- | ----------------- | --------------- |\n",
    "| IN      | 2                 | **Partition 2** |\n",
    "| US      | 0                 | Partition 0     |\n",
    "| UK      | 1                 | Partition 1     |\n",
    "| FR      | 3                 | Partition 3     |\n",
    "\n",
    "Now because 90% = IN:\n",
    "\n",
    "Partition 2 ‚Üí 90% of data üò±<br>\n",
    "Other partitions ‚Üí tiny<br>\n",
    "\n",
    "Key Rule (Very Important)<br>\n",
    "\n",
    "Spark does NOT distribute rows evenly<br>\n",
    "\n",
    "Spark groups rows by join key value, not by row count.<br>\n",
    "\n",
    "‚úÖ Solutions<br>\n",
    "‚úÖ Best: Broadcast JOIN (if one table is small)<br>\n",
    "What changes with BROADCAST JOIN<br>\n",
    "Key idea:<br>\n",
    "\n",
    "Small table is sent to every executor ‚Äî no shuffle on join key<br>\n",
    "Physical plan:<br>\n",
    "orders  ‚îÄ‚îÄ‚ñ∂ scan (NO shuffle)<br>\n",
    "customers ‚îÄ‚îÄ‚ñ∂ broadcast to all executors<br>\n",
    "\n",
    "\n",
    "SELECT /*+ BROADCAST(customers) */ *<br>\n",
    "FROM orders o<br>\n",
    "JOIN customers c<br>\n",
    "ON o.country = c.country;<br>\n",
    "\n",
    "‚úÖ Alternative: Salting\n",
    "Salting is used when both tables are large, so broadcast is impossible<br>\n",
    "-- Add salt on both sides<br>\n",
    "SELECT *<br>\n",
    "FROM orders o<br>\n",
    "JOIN customers c<br>\n",
    "ON o.country = c.country<br>\n",
    "AND o.salt = c.salt;<br>\n",
    "\n",
    "-----\n",
    "\n",
    "2Ô∏è‚É£ GROUP BY Skew<br>\n",
    "‚ùå Problem<br>\n",
    "\n",
    "Grouping on a dominant value<br>\n",
    "üß™ Example<br>\n",
    "\n",
    "SELECT country, COUNT(*)<br>\n",
    "FROM orders<br>\n",
    "GROUP BY country;<br>\n",
    "\n",
    "‚ö†Ô∏è Why Skew Happens\n",
    "\n",
    "One group (IN) holds most rows\n",
    "\n",
    "One reducer processes huge data\n",
    "\n",
    "In a GROUP BY, Spark repartitions the data by the grouping key, and each group key is assigned to exactly one <br>\n",
    "shuffle partition. If one key (like IN) has most rows, the task processing that partition becomes skewed.<br>\n",
    "\n",
    "For correctness:<br>\n",
    "All rows of the same country must be processed by the same task.<br>\n",
    "Otherwise Spark could not compute COUNT(*) correctly.<br>\n",
    "So Spark must collect all IN rows together.<br>\n",
    "\n",
    "‚úÖ Salting + Re-aggregation\n",
    "\n",
    "```sql\n",
    "-- Step 1: Salt\n",
    "WITH salted AS (\n",
    "  SELECT\n",
    "    country,\n",
    "    FLOOR(rand() * 10) AS salt\n",
    "  FROM orders\n",
    ")\n",
    "\n",
    "-- Step 2: Aggregation\n",
    "SELECT\n",
    "  country,\n",
    "  COUNT(*)\n",
    "FROM salted\n",
    "GROUP BY country;\n",
    "\n",
    "‚úÖ AQE (runtime fix)<br>\n",
    "SET spark.sql.adaptive.enabled = true;<br>\n",
    "SET spark.sql.adaptive.skewJoin.enabled = true;<br>\n",
    "-----\n",
    "3Ô∏è‚É£ Partitioning Skew (Delta / Hive)\n",
    "‚ùå Problem\n",
    "\n",
    "Partitioning by a skewed column\n",
    "\n",
    "üß™ Example\n",
    "\n",
    "```sql\n",
    "CREATE TABLE sales (\n",
    "  order_id INT,\n",
    "  country STRING\n",
    ")'''\n",
    "USING DELTA\n",
    "PARTITIONED BY (country);\n",
    "‚ö†Ô∏è Why Skew Happens\n",
    "\n",
    "country = IN folder contains most files\n",
    "\n",
    "Queries on that partition are slow\n",
    "\n",
    "Small countries ‚Üí tiny partitions\n",
    "\n",
    "‚úÖ Solutions\n",
    "\n",
    "‚úÖ Avoid partitioning\n",
    "CLUSTER BY (customer_id)\n",
    "\n",
    "‚úÖ Use Liquid Clustering\n",
    "CREATE TABLE sales\n",
    "USING DELTA\n",
    "CLUSTER BY (customer_id);\n",
    "\n",
    "\n",
    "4Ô∏è‚É£ ORDER BY Skew (Single Reducer Problem)\n",
    "‚ùå Problem\n",
    "\n",
    "Using ORDER BY\n",
    "\n",
    "üß™ Example\n",
    "SELECT *\n",
    "FROM orders\n",
    "ORDER BY order_date;\n",
    "\n",
    "‚ö†Ô∏è Why Skew Happens\n",
    "\n",
    "ORDER BY forces single reducer\n",
    "\n",
    "One task processes all data\n",
    "\n",
    "‚úÖ Solutions\n",
    "‚úÖ Use SORT BY\n",
    "SELECT *\n",
    "FROM orders\n",
    "SORT BY order_date;\n",
    "\n",
    "‚úÖ Or DISTRIBUTE BY + SORT BY\n",
    "SELECT *\n",
    "FROM orders\n",
    "DISTRIBUTE BY order_date\n",
    "SORT BY order_date;\n",
    "\n",
    "üéØ Interview Note\n",
    "\n",
    "ORDER BY = single partition ‚Üí guaranteed skew.\n",
    "\n",
    "5Ô∏è‚É£ Window Function Skew\n",
    "‚ùå Problem\n",
    "\n",
    "Window partition on skewed key\n",
    "\n",
    "üß™ Example\n",
    "SELECT *,\n",
    "       ROW_NUMBER() OVER (PARTITION BY country ORDER BY order_date)\n",
    "FROM orders;\n",
    "\n",
    "‚ö†Ô∏è Why Skew Happens\n",
    "\n",
    "All IN rows processed by one task\n",
    "\n",
    "‚úÖ Solutions\n",
    "‚úÖ Reduce partition size\n",
    "PARTITION BY country, year(order_date)\n",
    "\n",
    "‚úÖ Filter early\n",
    "WHERE order_date >= current_date() - 30\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cc8a5aa-52a7-4c87-9c93-20c4a1c2f12b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####1. Handling Data Skew & Query Performance (Optimize & Z-Order)\n",
    "Scenario: The analytics team reports that queries filtering silver_shipments by source_city and shipment_date are becoming slow as data volume grows.\n",
    "\n",
    "Task: Run the OPTIMIZE command with ZORDER on the silver_shipments table to co-locate related data in the same files.\n",
    "\n",
    "Outcome:\n",
    "Why did we choose source_city and shipment_date for Z-Ordering instead of shipment_id? Think about high cardinality vs. query filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b10785a-bbf8-432a-95b3-04233244ab07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE prodcatalog1.logistics1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d035063-cc2f-4d82-a82e-154d5789512b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM silver_shipments\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ed04e3f-5593-45fd-92ff-9334d5a2f762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Since queries are slow when filtering on source_city and shipment_date, we explicitly optimize file layout using Z-Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf274a83-7daf-41bd-a12f-53080b84473e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL silver_shipments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a797ec6f-38ce-4653-9939-0fe3ebb54087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "OPTIMIZE silver_shipments\n",
    "ZORDER BY (source_city,shipment_date);\n",
    "\n",
    "-- What this does\n",
    "-- Rewrites many small Delta files into fewer, larger files\n",
    "-- Physically co-locates rows with similar source_city and shipment_date\n",
    "-- Improves data skipping during query execution\n",
    "-- Reduces I/O and scan time for filter-heavy queries\n",
    "\n",
    "-- Z-ORDER is most effective on columns frequently used in query filters and with medium to low cardinality\n",
    "\n",
    "-- source_city\n",
    "-- Frequently used in WHERE clauses\n",
    "-- Limited set of values (cities repeat)\n",
    "-- High data locality benefit\n",
    "-- Enables skipping entire files when city doesn‚Äôt match\n",
    "\n",
    "-- Why NOT shipment_id\n",
    "--Very high cardinality AND Rarely used in filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e24d07a-e506-40e8-8993-1a370fb55447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL silver_shipments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18644ba2-cfe6-4ecf-af5e-fecc1e03eb1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. Speeding up Regional Queries (Partition Pruning)\n",
    "Scenario: The dashboard team reports that queries filtering for orgin_hub_city with \"New York\" shipments from the gold_core_curated_tbl table are scanning the entire dataset (Terabytes of data), even though New York is only 5% of the data. This is racking up compute costs.\n",
    "\n",
    "Task: Re-create the gold_core_curated_tbl table partitioned by orgin_hub_city. Run a query filtering for one city to demonstrate \"Partition Pruning\" (where Spark skips files that don't match the filter).\n",
    "\n",
    "Outcome: Verify the partition filtering is applied or not, by performing explain plan, check for the PartitionFilters in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48321341-307e-4225-b4db-43b86a85ff55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM core_curated_tbl\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f71dfea5-6e98-42ef-ae20-d9ba8dc1635a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE Gold_core_curated_tbl\n",
    "USING DELTA\n",
    "PARTITIONED BY (origin_hub_city)\n",
    "AS\n",
    "SELECT * FROM core_curated_tbl;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2097753d-a7a1-4990-bdc8-3c1bff1990d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "EXPLAIN select * from Gold_core_curated_tbl\n",
    "WHERE origin_hub_city = 'London'\n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "641167ea-25c5-4cf2-95b0-6e1d423e25c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESC DETAIL Gold_core_curated_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9f08453-afad-4fed-b6ae-0c853d6f298f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW PARTITIONS Gold_core_curated_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9aa6710-a2e0-47ae-82af-6b461e17939a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 3. Storage Cost Savings (Vacuum)\n",
    "Scenario: Your Project pipeline runs every hour, creating many small files and obsolete versions of data. Your storage costs are rising. You need to clean up files that are no longer needed for time travel.\n",
    "\n",
    "Task: Execute a Vacuum command to remove data files older than the retention threshold.\n",
    "\n",
    "Outcome: Perform the describe history and find whether vacuum is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76b94325-55b1-4ba3-bdc7-ef2e351afccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESC HISTORY core_curated_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6310ea73-574a-4b7d-ba7a-54d867f25075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "VACUUM core_curated_tbl RETAIN 168 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53b3a252-4afc-45c5-9fdc-ad634ba0ef9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESC HISTORY core_curated_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bfe48e9-7dd4-459e-94c9-586a88aac00f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####4. Modern Data Layout (Liquid Clustering)\n",
    "Scenario: You are redesigning the silver_shipments table. You want to avoid the \"small files\" problem and need a flexible layout that adapts to changing query patterns automatically without rewriting the table.\n",
    "\n",
    "Task: Re-create the silver_shipments table using Liquid Clustering on the shipment_id column.\n",
    "\n",
    "Outcome: Liquid Clustering over traditional partitioning when the cardinality of shipment_id is very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb806a0-ba51-48bf-acb1-a21018aa966b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE silver_shipments_liquid\n",
    "USING DELTA\n",
    "CLUSTER BY (shipment_id)\n",
    "AS\n",
    "SELECT * FROM silver_shipments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be8e50b7-6d66-47dd-b1c5-8e5b3078f4c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESC HISTORY silver_shipments_liquid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "397a62fe-7949-4f6a-86c0-c42c5ba9b73b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 5. Cost Efficient Environment Cloning (Shallow Clone)\n",
    "Scenario: The QA team needs to test an update on the gold_core_curated_tbl table. The table is 5TB in size. You cannot afford to duplicate the storage cost just for a test and the update should not affect the copied table.\n",
    "\n",
    "Task: Create a Shallow Clone of the gold table for the QA team.\n",
    "\n",
    "Outcome: If we delete records from the source table (gold_core_curated_tbl), will the QA table (gold_core_curated_tbl_qa) be affected? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3f3d924-ac8d-45ea-bcd2-34b145fd432a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM core_curated_tbl\n",
    "WHERE shipment_id=5010041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5476fa2-df16-4f2f-b6a9-4b3fb0fbde2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE core_curated_tbl_QA_Clone\n",
    "SHALLOW CLONE core_curated_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "649c15d2-4a60-4edb-8b72-2330917e7c15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM core_curated_tbl_QA_Clone\n",
    "WHERE shipment_id=5010041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f17ec87b-a6ce-411e-bccc-b04e627c893c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DELETE FROM core_curated_tbl_QA_Clone\n",
    "WHERE shipment_id=5010041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb22bcfc-2023-475b-a51b-99ffcf7d029f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM core_curated_tbl_QA_Clone\n",
    "WHERE shipment_id=5010041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dacb550e-9222-45a3-b4eb-f5efbbace8b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM core_curated_tbl\n",
    "WHERE shipment_id=5010041"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dedda2f9-9740-4d21-bf59-d38cb093dd48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Each table has its own transaction log, so deletes only change the metadata of the table where the operation is executed.\n",
    "\n",
    "A shallow clone points to the same data files as the original table, but it has its own transaction log. If a transaction happens on the original table, only the original table‚Äôs metadata is updated. No metadata changes are written to the clone, so the clone remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e3718b3-901e-4581-a985-c23892d8ec7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 6. Disaster Recovery (Time Travel & Restore)\n",
    "Scenario: A junior data engineer accidentally ran a logic error that corrupted the gold_core_curated_tbl table 15 minutes ago. You need to revert the table to its previous state immediately.\n",
    "\n",
    "Task: Use Delta Lake's Restore feature to roll back the table.\n",
    "\n",
    "Outcome:What is the difference between querying with VERSION AS OF (Time Travel) and running RESTORE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae024fd9-a247-4786-b56e-8807ba660a95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESC HISTORY core_curated_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a89adb-8900-4c85-84ca-d85bd0432b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM core_curated_tbl VERSION AS OF 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486eb75b-b67f-434b-87f7-a03aa23ddc9e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restore table to previous state"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Fix: Use a supported timestamp literal for RESTORE\n",
    "-- Example: RESTORE TABLE ... TO TIMESTAMP AS OF '2026-01-31T10:00:00Z'\n",
    "-- You can find the correct timestamp from DESC HISTORY output\n",
    "\n",
    "-- Replace with a valid timestamp from your table history\n",
    "RESTORE TABLE prodcatalog1.logistics1.core_curated_tbl TO TIMESTAMP AS OF '2026-01-31T10:00:00Z';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a2b44d7-4bf6-443f-adbf-a48a75e04579",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "restore table core_curated_tbl to version as of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08df47d5-07e1-4f3c-921d-ae33564c09f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Time Travel (VERSION AS OF) = temporary read of old data<br>\n",
    "- What happens\n",
    "- Only your query sees version 10\n",
    "- Other users still see the latest (broken) data\n",
    "- As soon as the query finishes ‚Üí old data is gone from view<br>\n",
    "Key point<br>\n",
    "‚ùå Table is NOT fixed<br>\n",
    "\n",
    "RESTORE = permanent rollback of the table<br>\n",
    "What happens\n",
    "- The table itself is rolled back\n",
    "- Everyone now sees version 10\n",
    "- A new version is created showing the restore action\n",
    "\n",
    "Key point\n",
    "‚úÖ Table IS fixed"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7818295663504426,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "delta_lake_house_optimization_costsaving_bestpractices_3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
