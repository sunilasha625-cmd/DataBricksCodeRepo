{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4316fe8c-3269-401b-b59c-db475f6fb3b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Delta Lake (Lakehouse Performance Optimization, Cost Saving & Best Practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92ccbf53-96e3-419c-883b-b80294502e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Delta Lake OPTIMIZE ‚Äì Internal Working (Deep Dive)\n",
    "\n",
    "## What problem OPTIMIZE solves\n",
    "\n",
    "Delta Lake tables often suffer from the **small files problem** due to:\n",
    "\n",
    "* Frequent `INSERT`s\n",
    "* `MERGE`, `UPDATE`, `DELETE` operations\n",
    "* Streaming writes\n",
    "\n",
    "Small files cause:\n",
    "\n",
    "* Excessive metadata reads\n",
    "* Slow query planning\n",
    "* Inefficient disk I/O\n",
    "\n",
    "üëâ **`OPTIMIZE` compacts many small files into fewer large files.**\n",
    "\n",
    "---\n",
    "\n",
    "## High-level definition\n",
    "\n",
    "```sql\n",
    "OPTIMIZE table_name;\n",
    "```\n",
    "\n",
    "> **OPTIMIZE rewrites data files by combining small Parquet files into fewer large Parquet files without changing table data or schema.**\n",
    "\n",
    "---\n",
    "\n",
    "## Internal Working (Step-by-Step)\n",
    "\n",
    "### Step 1: Read Delta Transaction Log (`_delta_log`)\n",
    "\n",
    "OPTIMIZE starts by scanning:\n",
    "\n",
    "```\n",
    "_delta_log/*.json\n",
    "```\n",
    "\n",
    "It identifies:\n",
    "\n",
    "* Active data files\n",
    "* File sizes\n",
    "* Partition information\n",
    "\n",
    "‚ùó Files already removed from the log are ignored.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Select candidate files\n",
    "\n",
    "Delta selects **small files** (typically < ~128MB):\n",
    "\n",
    "* Only within the **same partition**\n",
    "* Never mixes files across partitions\n",
    "\n",
    "Example:<br>\n",
    "region=North/file1 + file2 ‚Üí region=North/file_new<br>\n",
    "region=North/file1 + region=South/file3 ‚Üí one file:- Files from different partitions are never merged together.<br>\n",
    "\n",
    "\n",
    "```\n",
    "partition = 'North'\n",
    "  ‚îú‚îÄ‚îÄ file1 (10MB)\n",
    "  ‚îú‚îÄ‚îÄ file2 (20MB)\n",
    "  ‚îú‚îÄ‚îÄ file3 (15MB)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Spark reads selected files\n",
    "\n",
    "Spark:\n",
    "\n",
    "* Reads the selected small files into memory\n",
    "* Applies **no transformations**\n",
    "* Preserves rows exactly\n",
    "\n",
    "‚ö† No aggregation\n",
    "‚ö† No filtering\n",
    "‚ö† No deduplication\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Write new large files\n",
    "\n",
    "Spark writes:\n",
    "\n",
    "* Fewer Parquet files\n",
    "* Files close to target size (~128MB)\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Before OPTIMIZE:\n",
    "  10 files √ó 12MB\n",
    "\n",
    "After OPTIMIZE:\n",
    "  1 file √ó 120MB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Atomic Delta commit\n",
    "\n",
    "Delta performs an **atomic commit**:\n",
    "\n",
    "* `ADD` actions ‚Üí new optimized files\n",
    "* `REMOVE` actions ‚Üí old small files\n",
    "\n",
    "Results:\n",
    "\n",
    "* A **new table version**\n",
    "* No partial state visible to readers\n",
    "\n",
    "‚úî ACID guarantees preserved\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6: Logical deletion of old files\n",
    "\n",
    "Old small files:\n",
    "\n",
    "* Are marked as **removed** in the transaction log\n",
    "* Still exist physically in storage\n",
    "* Are invisible to queries\n",
    "\n",
    "Physical deletion happens only via:\n",
    "\n",
    "```sql\n",
    "VACUUM table_name;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## OPTIMIZE with Z-ORDER\n",
    "\n",
    "```sql\n",
    "OPTIMIZE table_name ZORDER BY (customer_id, region);\n",
    "```\n",
    "\n",
    "Additional behavior:\n",
    "\n",
    "* Rows are reordered using a **space-filling curve**\n",
    "* Related column values are colocated\n",
    "* Improves **data skipping** for selective queries\n",
    "\n",
    "‚ö† Z-ORDER is CPU and I/O intensive\n",
    "‚ö† Rewrites **all files in scope**\n",
    "\n",
    "---\n",
    "\n",
    "## What OPTIMIZE does NOT do\n",
    "\n",
    "| Myth               | Reality       |\n",
    "| ------------------ | ------------- |\n",
    "| Deletes files      | ‚ùå VACUUM does |\n",
    "| Changes data       | ‚ùå             |\n",
    "| Changes schema     | ‚ùå             |\n",
    "| Removes duplicates | ‚ùå             |\n",
    "| Repartitions table | ‚ùå             |\n",
    "\n",
    "---\n",
    "\n",
    "## Why OPTIMIZE is safe during reads\n",
    "\n",
    "Delta Lake ensures:\n",
    "\n",
    "* Readers see **either old or new snapshot**\n",
    "* Never partial or corrupted data\n",
    "\n",
    "This is guaranteed by:\n",
    "\n",
    "* Snapshot isolation\n",
    "* Versioned transaction log\n",
    "\n",
    "---\n",
    "\n",
    "## Performance impact\n",
    "\n",
    "**Before OPTIMIZE**\n",
    "\n",
    "```\n",
    "Query ‚Üí 1000 small files ‚Üí slow planning + I/O\n",
    "```\n",
    "\n",
    "**After OPTIMIZE**\n",
    "\n",
    "```\n",
    "Query ‚Üí 20 large files ‚Üí faster scan + pruning\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Production best practices\n",
    "\n",
    "Optimize only hot data:\n",
    "\n",
    "```sql\n",
    "OPTIMIZE table_name\n",
    "WHERE date >= current_date() - 7;\n",
    "```\n",
    "\n",
    "Benefits:\n",
    "\n",
    "* Avoids rewriting cold partitions\n",
    "* Reduces compute cost\n",
    "\n",
    "---\n",
    "\n",
    "## Interview-ready summary\n",
    "\n",
    "> **OPTIMIZE compacts small Delta files by reading active files from the transaction log, rewriting them into larger files per partition, and committing the changes atomically while logically removing old files.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d95a849a-250d-44eb-8786-021f0fa8f916",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use lakehousecat.deltadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6f5bcdd-61fc-4b98-8b28-8a6cf337281a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE tblsales\n",
    "(\n",
    "  sales_id INT,\n",
    "  product_id INT,\n",
    "  region STRING,\n",
    "  sales_amount DOUBLE,\n",
    "  sales_date DATE\n",
    ")\n",
    "USING DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "774db7e1-a4a3-437e-a38b-6cdaef211738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from tblsales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89dfe3d5-792f-4640-b510-cd9d4f0e72df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "INSERT INTO tblsales VALUES\n",
    "  (1, 101, 'North', 1000.50, '2025-10-16'),\n",
    "  (2, 102, 'South', 500.75, '2025-10-16'),\n",
    "  (3, 103, 'East', 700.20, '2025-10-16'),\n",
    "  (4, 104, 'West', 1200.00, '2025-10-16');\n",
    "\n",
    "INSERT INTO tblsales VALUES\n",
    "  (5, 101, 'North', 800.00, '2025-10-17'),\n",
    "  (6, 102, 'South', 450.00, '2025-10-17'),\n",
    "  (7, 103, 'East', 600.00, '2025-10-17'),\n",
    "  (8, 104, 'West', 1100.00, '2025-10-17');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79e60f6a-9276-4058-b3b7-421ea76211a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from tblsales;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bd92b0f-9e78-403b-bb45-bfe7beb9973c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Check fragmentation (numFiles & sizeInBytes)\n",
    "DESCRIBE DETAIL tblsales;\n",
    "\n",
    "-- Each INSERT is:\n",
    "-- One Delta transaction\n",
    "-- Produces one commit\n",
    "-- Writes one or more data files\n",
    "-- Because:\n",
    "-- Small data\n",
    "-- No repartitioning\n",
    "-- Default settings\n",
    "-- üëâ Each transaction produced 1 data file, so total files = 2\n",
    "-- Per transaction, Delta writes one or more files depending on Spark execution.\n",
    "-- 2. Data size\n",
    "-- Small inserts ‚Üí often 1 file\n",
    "-- Large inserts ‚Üí many files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86bfe408-5542-4c0c-8575-7b0c8831cea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Both numbers exist, but they mean different things.\n",
    "\n",
    "128 MB ‚Üí traditional Parquet / Spark best-practice target\n",
    "\n",
    "~1 GB ‚Üí Delta Lake OPTIMIZE default target file size\n",
    "\n",
    "So for Delta OPTIMIZE, the correct default is ~1 GB, not 128 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3106e7dd-e678-4ac1-936e-1b4b5a3df6a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Optimize the table\n",
    "--This performs file compaction:\n",
    "--Combines many small Parquet files into fewer large files (around 1 GB default).\n",
    "--Improves read performance and reduces metadata overhead.\n",
    "OPTIMIZE tblsales;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60f7f175-362b-4c91-bdb1-60c089c848b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify compaction\n",
    "-- After optimization, run:\n",
    "DESCRIBE DETAIL tblsales;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3991ee2-5874-4cc2-9001-156e80acbd4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. ZORDER\n",
    "- ZORDER is an optional feature used with OPTIMIZE to colocate related data physically in the same set of files by sorting.\n",
    "- Reduces file scan for queries filtering on ZORDER columns.\n",
    "- Works best for columns used frequently in WHERE clauses.\n",
    "\n",
    "#### EXAMPLE USE CASE:\n",
    "- Periodically optimize large Delta tables with frequent writes/updates.\n",
    "- Use ZORDER on high-selectivity/filtering columns to improve read performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "394f8721-0189-42dd-be05-b9ecf6cdcf2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Delta Lake Z-ORDER ‚Äî Explained with One Concrete Example\n",
    "\n",
    "## Scenario\n",
    "\n",
    "We have a **sales Delta table**:\n",
    "\n",
    "```sql\n",
    "CREATE TABLE tblsales (\n",
    "  order_id INT,\n",
    "  customer_id INT,\n",
    "  region STRING,\n",
    "  amount DOUBLE\n",
    ")\n",
    "USING DELTA\n",
    "PARTITIONED BY (region);\n",
    "```\n",
    "\n",
    "The table is frequently queried by **customer_id**.\n",
    "\n",
    "---\n",
    "\n",
    "## Data (inside one partition: `region = 'North'`)\n",
    "\n",
    "| order_id | customer_id | amount |\n",
    "| -------- | ----------- | ------ |\n",
    "| 1        | 101         | 500    |\n",
    "| 2        | 305         | 200    |\n",
    "| 3        | 102         | 800    |\n",
    "| 4        | 501         | 300    |\n",
    "| 5        | 103         | 900    |\n",
    "| 6        | 302         | 100    |\n",
    "\n",
    "Rows are written in **random order**.\n",
    "\n",
    "---\n",
    "\n",
    "## Without Z-ORDER (default layout)\n",
    "\n",
    "Files after normal OPTIMIZE:\n",
    "\n",
    "```\n",
    "region=North/\n",
    "  ‚îú‚îÄ‚îÄ file1 ‚Üí customer_id [101, 501]\n",
    "  ‚îú‚îÄ‚îÄ file2 ‚Üí customer_id [102, 305]\n",
    "  ‚îú‚îÄ‚îÄ file3 ‚Üí customer_id [103, 302]\n",
    "```\n",
    "\n",
    "### Query\n",
    "\n",
    "```sql\n",
    "SELECT * FROM tblsales\n",
    "WHERE region = 'North' AND customer_id = 101;\n",
    "```\n",
    "\n",
    "### What happens\n",
    "\n",
    "* Spark must scan **all 3 files**\n",
    "* Because 101 may exist anywhere\n",
    "\n",
    "‚ùå Poor data skipping\n",
    "\n",
    "---\n",
    "\n",
    "## OPTIMIZE with Z-ORDER\n",
    "\n",
    "```sql\n",
    "OPTIMIZE tblsales\n",
    "ZORDER BY (customer_id);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## How Z-ORDER rearranges data\n",
    "\n",
    "Z-ORDER:\n",
    "\n",
    "* Computes a **Z-value** for `customer_id`\n",
    "* Sorts rows by this Z-value\n",
    "* Writes rows with similar `customer_id` **together**\n",
    "\n",
    "Sorted order (conceptual):\n",
    "\n",
    "```\n",
    "101 ‚Üí 102 ‚Üí 103 ‚Üí 302 ‚Üí 305 ‚Üí 501\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## After Z-ORDER (new file layout)\n",
    "\n",
    "```\n",
    "region=North/\n",
    "  ‚îú‚îÄ‚îÄ file1 ‚Üí customer_id [101, 102, 103]\n",
    "  ‚îú‚îÄ‚îÄ file2 ‚Üí customer_id [302, 305]\n",
    "  ‚îú‚îÄ‚îÄ file3 ‚Üí customer_id [501]\n",
    "```\n",
    "\n",
    "Each file now covers a **tight min/max range**.\n",
    "\n",
    "---\n",
    "\n",
    "## Same query after Z-ORDER\n",
    "\n",
    "```sql\n",
    "SELECT * FROM tblsales\n",
    "WHERE region = 'North' AND customer_id = 101;\n",
    "```\n",
    "\n",
    "### File skipping logic\n",
    "\n",
    "| File  | customer_id min‚Äìmax | Read?  |\n",
    "| ----- | ------------------- | ------ |\n",
    "| file1 | 101‚Äì103             | ‚úÖ YES  |\n",
    "| file2 | 302‚Äì305             | ‚ùå SKIP |\n",
    "| file3 | 501‚Äì501             | ‚ùå SKIP |\n",
    "\n",
    "‚úÖ **Only 1 file scanned**\n",
    "\n",
    "---\n",
    "\n",
    "## Why performance improves\n",
    "\n",
    "* File-level statistics become precise\n",
    "* Spark skips irrelevant files\n",
    "* Less I/O, faster queries\n",
    "\n",
    "---\n",
    "\n",
    "## What Z-ORDER does NOT do\n",
    "\n",
    "* ‚ùå No index creation\n",
    "* ‚ùå No data filtering\n",
    "* ‚ùå No deduplication\n",
    "* ‚ùå No cross-partition mixing\n",
    "\n",
    "---\n",
    "\n",
    "## One-line interview takeaway\n",
    "\n",
    "> **Z-ORDER physically colocates similar column values inside Delta files so that selective queries scan fewer files using data skipping.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91142f64-6e62-45c9-af47-304c876c863f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Delta Lake OPTIMIZE & Z-ORDER ‚Äî Use Case Explained\n",
    "\n",
    "This document explains **why and when** `OPTIMIZE` and `Z-ORDER` are used in real-world Delta Lake systems, using a **practical production scenario**.\n",
    "\n",
    "---\n",
    "\n",
    "## Real-world scenario: E-commerce Orders Table\n",
    "\n",
    "### Table\n",
    "\n",
    "```sql\n",
    "orders_delta\n",
    "```\n",
    "\n",
    "### Data ingestion pattern\n",
    "\n",
    "* Streaming job inserts new orders every **5 minutes**\n",
    "* CDC job performs `MERGE` every **hour**\n",
    "* Millions of rows added daily\n",
    "\n",
    "This is a **write-heavy Delta table**.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 1: Why OPTIMIZE is needed\n",
    "\n",
    "### What happens without OPTIMIZE\n",
    "\n",
    "Every write creates small Parquet files:\n",
    "\n",
    "```\n",
    "Day 1  ‚Üí 2,000 files (5‚Äì20 MB)\n",
    "Day 2  ‚Üí 4,000 files\n",
    "Day 7  ‚Üí 15,000+ files\n",
    "```\n",
    "\n",
    "### Query example\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM orders_delta\n",
    "WHERE order_date = '2026-01-28';\n",
    "```\n",
    "\n",
    "Even though only one day is queried:\n",
    "\n",
    "* Spark must open **thousands of files**\n",
    "* Query planning and I/O become slow\n",
    "\n",
    "‚ùå Data is correct\n",
    "‚ùå Performance is poor\n",
    "\n",
    "---\n",
    "\n",
    "## OPTIMIZE use case\n",
    "\n",
    "### Business requirement\n",
    "\n",
    "> Queries on **recent orders** must be fast.\n",
    "\n",
    "### Solution\n",
    "\n",
    "Run `OPTIMIZE` **periodically** (for example, once per day):\n",
    "\n",
    "```sql\n",
    "OPTIMIZE orders_delta\n",
    "WHERE order_date >= current_date() - 7;\n",
    "```\n",
    "\n",
    "### Result\n",
    "\n",
    "* Small files are compacted into large files (~1 GB)\n",
    "* File count is drastically reduced\n",
    "* Queries become significantly faster\n",
    "\n",
    "‚úÖ This is the **OPTIMIZE use case**\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 2: Why Z-ORDER is needed\n",
    "\n",
    "Even after OPTIMIZE, data inside files is **not ordered**.\n",
    "\n",
    "Example layout:\n",
    "\n",
    "```\n",
    "region=US/\n",
    "  ‚îú‚îÄ‚îÄ file1 ‚Üí customer_id [1 ‚Ä¶ 1,000,000]\n",
    "  ‚îú‚îÄ‚îÄ file2 ‚Üí customer_id [1 ‚Ä¶ 1,000,000]\n",
    "```\n",
    "\n",
    "Each file contains a wide range of customers.\n",
    "\n",
    "---\n",
    "\n",
    "## Query pattern that causes slowness\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM orders_delta\n",
    "WHERE customer_id = 987654;\n",
    "```\n",
    "\n",
    "Spark still:\n",
    "\n",
    "* Scans many large files\n",
    "* Because the customer‚Äôs data is spread everywhere\n",
    "\n",
    "‚ùå File count is low\n",
    "‚ùå File skipping is ineffective\n",
    "\n",
    "---\n",
    "\n",
    "## Z-ORDER use case\n",
    "\n",
    "### Business requirement\n",
    "\n",
    "> Customer-specific queries must be fast.\n",
    "\n",
    "### Solution\n",
    "\n",
    "Apply Z-ORDER on a **high-selectivity column**:\n",
    "\n",
    "```sql\n",
    "OPTIMIZE orders_delta\n",
    "WHERE order_date >= current_date() - 7\n",
    "ZORDER BY (customer_id);\n",
    "```\n",
    "\n",
    "### Result\n",
    "\n",
    "* Rows for the same `customer_id` are physically colocated\n",
    "* File-level min/max statistics become tighter\n",
    "* Only a few files are scanned per query\n",
    "\n",
    "‚úÖ This is the **Z-ORDER use case**\n",
    "\n",
    "---\n",
    "\n",
    "## Why OPTIMIZE and Z-ORDER are used together\n",
    "\n",
    "They solve **different but complementary problems**:\n",
    "\n",
    "| Problem                | Feature  |\n",
    "| ---------------------- | -------- |\n",
    "| Too many small files   | OPTIMIZE |\n",
    "| Too many files scanned | Z-ORDER  |\n",
    "\n",
    "Combined usage improves both:\n",
    "\n",
    "* Write efficiency\n",
    "* Read performance\n",
    "\n",
    "---\n",
    "\n",
    "## Simple mental model\n",
    "\n",
    "* **OPTIMIZE** ‚Üí fixes *how many files exist*\n",
    "* **Z-ORDER** ‚Üí fixes *which files are read*\n",
    "\n",
    "---\n",
    "\n",
    "## Interview-ready summary\n",
    "\n",
    "> **In large Delta tables with frequent writes, OPTIMIZE is run periodically to compact small files, and Z-ORDER is applied on high-selectivity columns to ensure selective queries scan fewer files and perform faster.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c02a7b2e-a00c-46f0-b2ba-33375b53770e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "-- Step 1 ‚Äì Create the Delta table\n",
    "use lakehousecat.deltadb;\n",
    "CREATE OR REPLACE TABLE customer_txn (\n",
    "    txn_id INT,\n",
    "    customer_id INT,\n",
    "    region STRING,\n",
    "    txn_amount DOUBLE,\n",
    "    txn_type STRING,\n",
    "    transaction_date DATE\n",
    ")\n",
    "USING DELTA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39087b18-07e6-462b-959d-de89afdf09f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "describe history customer_txn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07896723-193d-4f35-9ddb-7eac2adbd341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Step 2 ‚Äì Insert multiple small batches\n",
    "--Each insert writes a few small Parquet files.\n",
    "-- Batch 1\n",
    "INSERT INTO customer_txn VALUES\n",
    " (1, 1001, 'North', 250.00, 'Online', '2025-10-01'),\n",
    " (2, 1002, 'South', 400.00, 'Offline', '2025-10-02'),\n",
    " (3, 1003, 'West', 600.00, 'Online', '2025-10-03');\n",
    "\n",
    "-- Batch 2\n",
    "INSERT INTO customer_txn VALUES\n",
    " (4, 1001, 'North', 300.00, 'Offline', '2025-10-01'),\n",
    " (5, 1004, 'East', 750.00, 'Online', '2025-10-02'),\n",
    " (6, 1005, 'South', 180.00, 'Online', '2025-10-03');\n",
    "\n",
    "-- Batch 3\n",
    "INSERT INTO customer_txn VALUES\n",
    " (7, 1001, 'North', 270.00, 'Online', '2025-10-01'),\n",
    " (8, 1003, 'West', 500.00, 'Offline', '2025-10-02'),\n",
    " (9, 1002, 'South', 900.00, 'Online', '2025-10-03');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2e0200a-d08a-4995-aa95-63de6123563b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# OPTIMIZE vs Z-ORDER ‚Äî Simple File‚ÄëLevel Explanation\n",
    "\n",
    "This document explains **what is happening** in the example step by step, in **very simple terms**, focusing only on **files and folders**.\n",
    "\n",
    "---\n",
    "\n",
    "## Table setup\n",
    "\n",
    "```sql\n",
    "customer_txn\n",
    "PARTITIONED BY (region)\n",
    "```\n",
    "\n",
    "This means **each region is a folder**.\n",
    "\n",
    "---\n",
    "\n",
    "## STEP 1: Before OPTIMIZE\n",
    "\n",
    "```\n",
    "region=North\n",
    "    part-0\n",
    "    part-1\n",
    "    part-2\n",
    "region=South\n",
    "    part-0\n",
    "    part-1\n",
    "    part-2\n",
    "region=West\n",
    "    part-0\n",
    "    part-1\n",
    "region=East\n",
    "    part-0\n",
    "```\n",
    "\n",
    "### What this means\n",
    "\n",
    "* Each `region` folder has **multiple small files**\n",
    "* Rows inside files are in **random order**\n",
    "\n",
    "### Query example\n",
    "\n",
    "```sql\n",
    "SELECT * FROM customer_txn WHERE region = 'North';\n",
    "```\n",
    "\n",
    "Spark behavior:\n",
    "\n",
    "* Goes only to `region=North/` folder (partition pruning)\n",
    "* Reads **all files inside that folder**\n",
    "\n",
    "---\n",
    "\n",
    "## STEP 2: After `OPTIMIZE customer_txn`\n",
    "\n",
    "```\n",
    "region=North\n",
    "    part-3   ‚Üê new large file\n",
    "region=South\n",
    "    part-3\n",
    "region=West\n",
    "    part-2\n",
    "region=East\n",
    "    part-1\n",
    "```\n",
    "\n",
    "(Old files are logically removed)\n",
    "\n",
    "### What OPTIMIZE does\n",
    "\n",
    "* Reads all small files **within the same region**\n",
    "* Combines them into **fewer, larger files**\n",
    "* Creates a **new Delta version**\n",
    "\n",
    "### What OPTIMIZE does NOT do\n",
    "\n",
    "* ‚ùå Does NOT sort rows\n",
    "* ‚ùå Does NOT mix regions\n",
    "\n",
    "### Benefit\n",
    "\n",
    "* Fewer files to read\n",
    "* Faster queries\n",
    "\n",
    "---\n",
    "\n",
    "## STEP 3: OPTIMIZE with Z-ORDER\n",
    "\n",
    "```sql\n",
    "OPTIMIZE customer_txn\n",
    "ZORDER BY (transaction_date);\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## STEP 4: After `OPTIMIZE + ZORDER`\n",
    "\n",
    "```\n",
    "region=North\n",
    "    part-3   ‚Üê rows grouped by transaction_date\n",
    "region=South\n",
    "    part-3   ‚Üê rows grouped by transaction_date\n",
    "region=West\n",
    "    part-2   ‚Üê rows grouped by transaction_date\n",
    "region=East\n",
    "    part-1   ‚Üê rows grouped by transaction_date\n",
    "```\n",
    "\n",
    "### What Z-ORDER does\n",
    "\n",
    "* Rewrites files again\n",
    "* **Arranges rows inside each file**\n",
    "* Keeps similar `transaction_date` values close together\n",
    "\n",
    "---\n",
    "\n",
    "## Why Z-ORDER helps\n",
    "\n",
    "Query:\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM customer_txn\n",
    "WHERE region = 'North'\n",
    "  AND transaction_date = '2026-01-02';\n",
    "```\n",
    "\n",
    "### Without Z-ORDER\n",
    "\n",
    "* Entire file must be scanned\n",
    "\n",
    "### With Z-ORDER\n",
    "\n",
    "* Spark checks file metadata (min/max date)\n",
    "* Skips irrelevant data\n",
    "* Reads much less data\n",
    "\n",
    "---\n",
    "\n",
    "## Very simple analogy\n",
    "\n",
    "* **Partition (region)** ‚Üí folders\n",
    "* **Files** ‚Üí notebooks\n",
    "* **OPTIMIZE** ‚Üí combine many notebooks into one\n",
    "* **Z-ORDER** ‚Üí sort pages inside the notebook\n",
    "\n",
    "---\n",
    "\n",
    "## One-line takeaway (important)\n",
    "\n",
    "> **OPTIMIZE reduces the number of files per partition, and Z-ORDER arranges rows inside those files so queries scan less data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a00d017-5e81-4f08-8b9b-85000ec8b34b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "describe history customer_txn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d51373a4-7903-45f8-af14-95a42a07ce7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Step 3 ‚Äì Inspect fragmentation (numFiles & sizeInBytes)\n",
    "DESCRIBE DETAIL customer_txn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a891e125-7d68-4856-bf7c-387b36464066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Step 4 ‚Äì Run OPTIMIZE ZORDER - watch out the metrics - zOrderStats\n",
    "-- Now compact and physically order data.\n",
    "OPTIMIZE customer_txn \n",
    "ZORDER BY (transaction_date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c58c1ce-3c6d-42c1-ae75-dd53d25121a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY customer_txn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76dac5a9-dca0-42cd-9b7b-9534ca41228c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Step 3 ‚Äì Inspect fragmentation\n",
    "DESCRIBE DETAIL customer_txn;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74e6330-8d5f-4287-b0ad-a310f3ed66ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "OPTIMIZE rewrites Parquet files, so metadata is regenerated per new file; the data content remains the same, but total file size may change slightly due to improved compression and reduced metadata overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b01f4d06-abaf-4a8a-8301-e11fd05b7f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####3. Partitioning\n",
    "Partitioning is the practice of physically splitting a table's data into separate **folders** based on a column.<br>\n",
    "Good partition columns:<br>\n",
    "- Low cardinality (low difference columns such as date, age, city, region, gender)\n",
    "- Columns used Frequently used in filters\n",
    "- Stable (we can't change the partition columns very frequently)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dd49e33-eb7e-4b02-9ad0-c345403a41a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Partitioning in Delta Lake ‚Äî Detailed Explanation\n",
    "\n",
    "This document explains **partitioning** step by step: what it is, why it exists, how Spark/Delta use it internally, and how it works together with OPTIMIZE and Z-ORDER.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Partitioning? (Plain English)\n",
    "\n",
    "> **Partitioning means physically splitting table data into folders based on column values.**\n",
    "\n",
    "* Each partition = **one folder**\n",
    "* Each folder contains rows for **only one partition value**\n",
    "\n",
    "---\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "```sql\n",
    "CREATE TABLE customer_txn (\n",
    "  txn_id INT,\n",
    "  customer_id INT,\n",
    "  region STRING,\n",
    "  transaction_date DATE,\n",
    "  amount DOUBLE\n",
    ")\n",
    "USING DELTA\n",
    "PARTITIONED BY (region);\n",
    "```\n",
    "\n",
    "### Physical layout in storage\n",
    "\n",
    "```\n",
    "customer_txn/\n",
    "  ‚îú‚îÄ‚îÄ region=North/\n",
    "  ‚îÇ     ‚îú‚îÄ‚îÄ part-000.parquet\n",
    "  ‚îÇ     ‚îú‚îÄ‚îÄ part-001.parquet\n",
    "  ‚îú‚îÄ‚îÄ region=South/\n",
    "  ‚îÇ     ‚îú‚îÄ‚îÄ part-000.parquet\n",
    "  ‚îú‚îÄ‚îÄ region=West/\n",
    "  ‚îÇ     ‚îú‚îÄ‚îÄ part-000.parquet\n",
    "```\n",
    "\n",
    "Each folder contains **only that region‚Äôs data**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Partitioning Exists (Very Important)\n",
    "\n",
    "Partitioning exists mainly for **partition pruning**:\n",
    "\n",
    "> **Avoid reading unnecessary data.**\n",
    "\n",
    "---\n",
    "\n",
    "## Query Without Partitioning\n",
    "\n",
    "```sql\n",
    "SELECT * FROM customer_txn WHERE region = 'North';\n",
    "```\n",
    "\n",
    "* Spark scans the **entire table**\n",
    "* Filters rows after reading\n",
    "\n",
    "‚ùå Slow\n",
    "‚ùå Expensive\n",
    "\n",
    "---\n",
    "\n",
    "## Query With Partitioning\n",
    "\n",
    "Same query:\n",
    "\n",
    "```sql\n",
    "SELECT * FROM customer_txn WHERE region = 'North';\n",
    "```\n",
    "\n",
    "Spark behavior:\n",
    "\n",
    "* Reads only `region=North/`\n",
    "* Skips South, West, East folders\n",
    "\n",
    "‚úÖ Fast\n",
    "‚úÖ Cheap\n",
    "\n",
    "This is called **partition pruning**.\n",
    "\n",
    "---\n",
    "\n",
    "## How Spark Uses Partitioning Internally\n",
    "\n",
    "1. Spark analyzes the query\n",
    "2. Detects filter on partition column\n",
    "3. Reads table metadata\n",
    "4. Prunes irrelevant folders\n",
    "5. Scans only matching partitions\n",
    "\n",
    "---\n",
    "\n",
    "## Partitioning vs Spark Partitions (Common Confusion)\n",
    "\n",
    "| Concept         | Meaning                    |\n",
    "| --------------- | -------------------------- |\n",
    "| Delta partition | Physical folder in storage |\n",
    "| Spark partition | Parallel execution task    |\n",
    "\n",
    "They are **not the same**.\n",
    "\n",
    "---\n",
    "\n",
    "## Good Partition Columns (Rules of Thumb)\n",
    "\n",
    "A good partition column:\n",
    "\n",
    "* Low to medium cardinality\n",
    "* Frequently used in filters\n",
    "* Grows naturally over time\n",
    "\n",
    "### Good examples\n",
    "\n",
    "* `date`\n",
    "* `region`\n",
    "* `country`\n",
    "* `year`, `month`\n",
    "\n",
    "### Bad examples\n",
    "\n",
    "* `customer_id`\n",
    "* `order_id`\n",
    "* `uuid`\n",
    "* `transaction_id`\n",
    "\n",
    "---\n",
    "\n",
    "## Why High-Cardinality Partitioning Is Bad\n",
    "\n",
    "Partitioning by `customer_id` creates:\n",
    "\n",
    "```\n",
    "customer_id=1/\n",
    "customer_id=2/\n",
    "customer_id=3/\n",
    "...\n",
    "```\n",
    "\n",
    "Problems:\n",
    "\n",
    "* Millions of folders\n",
    "* Huge metadata overhead\n",
    "* Slow query planning\n",
    "* OPTIMIZE becomes ineffective\n",
    "\n",
    "‚ùå Anti-pattern\n",
    "\n",
    "---\n",
    "\n",
    "## Partitioning + OPTIMIZE\n",
    "\n",
    "Partitioning decides:\n",
    "\n",
    "> **Which folder to read**\n",
    "\n",
    "OPTIMIZE decides:\n",
    "\n",
    "> **How many files inside the folder**\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "region=North/\n",
    "  part-0 (5MB)\n",
    "  part-1 (7MB)\n",
    "  part-2 (6MB)\n",
    "```\n",
    "\n",
    "After OPTIMIZE:\n",
    "\n",
    "```\n",
    "region=North/\n",
    "  part-3 (18MB)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Partitioning + Z-ORDER\n",
    "\n",
    "Partitioning:\n",
    "\n",
    "* Prunes folders\n",
    "\n",
    "Z-ORDER:\n",
    "\n",
    "* Skips files **inside folders**\n",
    "\n",
    "Query example:\n",
    "\n",
    "```sql\n",
    "WHERE region = 'North'\n",
    "  AND transaction_date = '2026-01-15'\n",
    "```\n",
    "\n",
    "Execution order:\n",
    "\n",
    "1. Partition pruning ‚Üí folder selection\n",
    "2. Z-ORDER ‚Üí file skipping\n",
    "\n",
    "---\n",
    "\n",
    "## Multi-Column Partitioning\n",
    "\n",
    "```sql\n",
    "PARTITIONED BY (year, month)\n",
    "```\n",
    "\n",
    "Storage layout:\n",
    "\n",
    "```\n",
    "year=2026/\n",
    "  month=01/\n",
    "  month=02/\n",
    "```\n",
    "\n",
    "‚ö† Too many partition columns cause deep folder structures\n",
    "‚ö† Over-partitioning hurts performance\n",
    "\n",
    "---\n",
    "\n",
    "## When NOT to Use Partitioning\n",
    "\n",
    "* Small tables\n",
    "* Columns rarely used in filters\n",
    "* High-cardinality columns\n",
    "* Temporary or exploratory data\n",
    "\n",
    "---\n",
    "\n",
    "## Interview-Ready Summary\n",
    "\n",
    "> **Partitioning physically organizes data into folders based on column values, enabling Spark to prune irrelevant data and scan only what is required.**\n",
    "\n",
    "---\n",
    "\n",
    "## One-Line Mental Model\n",
    "\n",
    "* Partitioning ‚Üí which folders to read\n",
    "* OPTIMIZE ‚Üí how many files inside\n",
    "* Z-ORDER ‚Üí which files inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22cf7760-b047-4d55-9965-b74118b305e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use lakehousecat.deltadb;\n",
    "CREATE OR REPLACE TABLE customer_txn_part1 (\n",
    "    txn_id INT,\n",
    "    customer_id INT,\n",
    "    region STRING,\n",
    "    txn_amount DOUBLE,\n",
    "    txn_type STRING,\n",
    "    transaction_date DATE\n",
    ") \n",
    "using delta\n",
    "partitioned by (transaction_date);\n",
    "insert into customer_txn_part1 select * from customer_txn;\n",
    "--or\n",
    "create or replace table customer_txn_part \n",
    "partitioned by (transaction_date) \n",
    "as select * from customer_txn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9807bac-5f3e-496b-a698-242c10c9499b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "explain select * from customer_txn_part1 where transaction_date='2025-10-01';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "123bcb81-5a67-4c05-9a65-a86252f88697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "#Just to show you how the data is partitioned in the filesystem (behind the scene)\n",
    "spark.sql(\"select * from customer_txn\").write.partitionBy(\"region\").format(\"delta\").save(\"/Volumes/lakehousecat/deltadb/datalake/cust_txns_partdelta\")\n",
    "\n",
    "\n",
    "#equivalent CTAS in Pyspark python programming\n",
    "spark.sql(\"select * from customer_txn\").write.partitionBy(\"region\").saveAsTable(\"customer_txn_part2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0bffd5c-6688-4ad8-bdab-edd53388a2c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql('SHOW PARTITIONS customer_txn_part'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f11cfb1e-c603-48c8-ac69-42529e4516b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"SHOW PARTITIONS customer_txn_part2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2216b6e6-52da-4025-9318-75ba7f946ac3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM customer_txn_part\n",
    "WHERE transaction_date BETWEEN '2025-10-01' AND '2025-10-01';--picks the data from the 2025-10-01 folder directly and show the result quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e19aae2-69c2-420d-9963-83c84233666e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####4. Vaccum\n",
    "*VACUUM* in Delta Lake removes old, unused files to free up storage, default retention hours is 168. These files come from operations like DELETE, UPDATE, or MERGE and are kept temporarily so time-travel queries can work.<br>\n",
    "\n",
    "Before VACUUM<br>\n",
    "Active + deleted parquet files exist<br>\n",
    "\n",
    "After VACUUM<br>\n",
    "Only ACTIVE parquet files remains and delete Old parquet files (from UPDATE/MERGE/DELETE)<br>\n",
    "Logs remain maintained (will not delete logs, only old data deleted)<br>\n",
    "Time travel beyond retention becomes impossible<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7fea36a-ecc1-496a-bc1b-1cd0808cdee2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "VACUUM drugstbl_merge RETAIN 168 HOURS;\n",
    "--SET spark.databricks.delta.retentionDurationCheck.enabled = false;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34b5b2c9-ea63-4b33-b9f8-053edf673ed4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Active vs Deleted Parquet Files (Before VACUUM)\n",
    "\n",
    "This document explains **what it means when we say**:\n",
    "\n",
    "> **Before VACUUM: Active + deleted parquet files exist**\n",
    "\n",
    "in the simplest and clearest way.\n",
    "\n",
    "---\n",
    "\n",
    "## Very Important Rule (Read First)\n",
    "\n",
    "> **In Delta Lake, DELETE does NOT mean the file is removed from storage.**\n",
    "\n",
    "Delta Lake uses **logical deletion**, not physical deletion.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Initial state (no changes yet)\n",
    "\n",
    "Parquet files in storage:\n",
    "\n",
    "```\n",
    "part-0.parquet\n",
    "part-1.parquet\n",
    "part-2.parquet\n",
    "```\n",
    "\n",
    "All files are:\n",
    "\n",
    "* Active\n",
    "* Used by queries\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: A write operation happens\n",
    "\n",
    "You run any of the following:\n",
    "\n",
    "* `OPTIMIZE`\n",
    "* `UPDATE`\n",
    "* `DELETE`\n",
    "* `MERGE`\n",
    "\n",
    "Delta Lake:\n",
    "\n",
    "1. Creates **new Parquet file(s)**\n",
    "2. Marks old files as **REMOVED in metadata**\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "part-3.parquet   ‚Üê new file\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: What exists AFTER the operation\n",
    "\n",
    "### Physically on storage (S3 / ADLS / DBFS)\n",
    "\n",
    "```\n",
    "part-0.parquet   ‚Üê exists\n",
    "part-1.parquet   ‚Üê exists\n",
    "part-2.parquet   ‚Üê exists\n",
    "part-3.parquet   ‚Üê exists\n",
    "```\n",
    "\n",
    "### Logically in Delta metadata (`_delta_log`)\n",
    "\n",
    "* **Active files** (used by queries)\n",
    "\n",
    "  * `part-3.parquet`\n",
    "\n",
    "* **Deleted files (logical)**\n",
    "\n",
    "  * `part-0.parquet`\n",
    "  * `part-1.parquet`\n",
    "  * `part-2.parquet`\n",
    "\n",
    "üëâ This state is called:\n",
    "\n",
    "> **Active + deleted parquet files exist**\n",
    "\n",
    "---\n",
    "\n",
    "## What ‚Äúdeleted parquet files‚Äù really means\n",
    "\n",
    "Deleted parquet files:\n",
    "\n",
    "* Are **NOT visible** to current queries\n",
    "* Are **NOT counted** in table metadata\n",
    "* **DO still exist physically** on storage\n",
    "\n",
    "This is called **logical deletion**.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Delta keeps deleted files\n",
    "\n",
    "Delta Lake keeps old files for:\n",
    "\n",
    "### 1. Time travel\n",
    "\n",
    "```sql\n",
    "SELECT * FROM table VERSION AS OF 10;\n",
    "```\n",
    "\n",
    "### 2. Running queries safety\n",
    "\n",
    "Queries started earlier can still read old files.\n",
    "\n",
    "### 3. ACID guarantees\n",
    "\n",
    "No partial or corrupted reads.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: What VACUUM does\n",
    "\n",
    "```sql\n",
    "VACUUM table_name;\n",
    "```\n",
    "\n",
    "VACUUM:\n",
    "\n",
    "* Permanently deletes **logically removed files**\n",
    "* Keeps only active files\n",
    "* Frees storage space\n",
    "\n",
    "### After VACUUM\n",
    "\n",
    "```\n",
    "part-3.parquet   ‚Üê exists\n",
    "part-0.parquet   ‚Üê deleted ‚ùå\n",
    "part-1.parquet   ‚Üê deleted ‚ùå\n",
    "part-2.parquet   ‚Üê deleted ‚ùå\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Key difference to remember\n",
    "\n",
    "| Term         | Meaning                                 |\n",
    "| ------------ | --------------------------------------- |\n",
    "| Active file  | Used by current table version           |\n",
    "| Deleted file | Removed from metadata, still on storage |\n",
    "| OPTIMIZE     | Logical delete + rewrite                |\n",
    "| VACUUM       | Physical delete                         |\n",
    "\n",
    "---\n",
    "\n",
    "## One-line summary (Interview-ready)\n",
    "\n",
    "> **Before VACUUM, Delta tables contain both active Parquet files used by the current version and logically deleted Parquet files that still exist on storage for time travel and consistency.**\n",
    "\n",
    "---\n",
    "\n",
    "## Ultra-short mental model\n",
    "\n",
    "* OPTIMIZE / DELETE ‚Üí logical delete\n",
    "* Files still exist\n",
    "* VACUUM ‚Üí physical delete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "288a4b26-5ca7-4530-8931-5071b6f4a8f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####5. Liquid Clustering\n",
    "*Liquid Clustering is the* Next-generation data clustering feature that automatically manages physical data organization on disk to minimize scan cost for frequently queried columns only on Delta tables by performing automatic Z-Ordering, Partitioning and Optimize.<br>\n",
    "while clustering in databricks delta does partition happens literally?\n",
    "No, liquid clustering does not create literal physical partitions (subdirectories). \n",
    "still we get the benifits of partitioning while doing clustering?\n",
    "Yes, you absolutely still get the benefits of partitioning while doing clustering.\n",
    "\n",
    "**Partition vs Liquid Clustering**\n",
    "| Use case                       | Recommendation         |\n",
    "| ------------------------------ | ---------------------- |\n",
    "| High-cardinality columns       | Liquid clustering    |\n",
    "| Frequently changing filters    | Liquid clustering    |\n",
    "| Streaming / incremental loads  | Liquid clustering    |\n",
    "| Static, low-cardinality (date) | Partition OR Liquid |\n",
    "| Legacy Hive-style tables       | Partition           |\n",
    "\n",
    "\n",
    "**Typical Use Cases**\n",
    "- Large tables with frequent inserts, updates, and deletes.\n",
    "- Query filtering on specific columns like customer_id, region, order_date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73e5a448-5862-4f90-8591-00b7ade21977",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Running OPTIMIZE at table creation time only optimizes the data that exists at that moment. Any new inserts/appends after that are NOT optimized.\n",
    "\n",
    "Why this happens (conceptually)\n",
    "\n",
    "Delta Lake stores data as immutable files.\n",
    "\n",
    "CREATE TABLE ‚Üí creates metadata\n",
    "\n",
    "Initial INSERT / CTAS ‚Üí creates data files\n",
    "\n",
    "OPTIMIZE ‚Üí rewrites those existing files only\n",
    "\n",
    "Later INSERT / STREAMING WRITE ‚Üí new files are added\n",
    "\n",
    "Those new files remain unoptimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49d283e4-d089-42c8-9d05-6e33a6118aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Feature                        | Manual or Automatic?            | Why                                               |\n",
    "| ------------------------------ | ------------------------------- | ------------------------------------------------- |\n",
    "| **Z-ORDER**                    | ‚úÖ **Manual**                    | Runs only when you execute `OPTIMIZE ‚Ä¶ ZORDER BY` |\n",
    "| **OPTIMIZE (file compaction)** | ‚ö†Ô∏è **Manual by default**        | Rewrites files only when triggered                |\n",
    "| **PARTITION BY**               | ‚ùå **NOT manual after creation** | Applied **at write time**, not rerun              |\n",
    "| **Liquid Clustering**          | ‚úÖ **Automatic**                 | Clusters data during new writes                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10c543a7-0a1c-41b5-8e0e-cd59b488da92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Liquid Clustering in Delta Lake ‚Äî Detailed Explanation (with Example)\n",
    "\n",
    "This document explains **Liquid Clustering** clearly and completely: what it is, why it exists, how it works internally, how it differs from partitioning and Z-ORDER, and when to use it ‚Äî with a concrete example.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Liquid Clustering? (Plain English)\n",
    "\n",
    "> **Liquid Clustering is a dynamic data layout technique in Delta Lake that automatically organizes data based on frequently filtered columns, without fixed partitions.**\n",
    "\n",
    "Key idea:\n",
    "\n",
    "* No static folders like partitioning\n",
    "* No manual reorganization like Z-ORDER\n",
    "* Delta automatically **maintains clustering over time**\n",
    "\n",
    "---\n",
    "\n",
    "## Why Liquid Clustering Exists\n",
    "\n",
    "Traditional approaches have problems:\n",
    "\n",
    "### Partitioning problems\n",
    "\n",
    "* Fixed at table creation\n",
    "* Over-partitioning causes too many folders\n",
    "* Under-partitioning causes large scans\n",
    "* Hard to change later\n",
    "\n",
    "### Z-ORDER problems\n",
    "\n",
    "* Manual operation\n",
    "* Expensive full rewrites\n",
    "* Clustering degrades with new writes\n",
    "\n",
    "üëâ **Liquid Clustering solves both.**\n",
    "\n",
    "---\n",
    "\n",
    "## How Liquid Clustering Works (High Level)\n",
    "\n",
    "1. You define **clustering columns**\n",
    "2. Delta tracks clustering metadata\n",
    "3. New writes are **automatically clustered**\n",
    "4. Background optimization maintains layout\n",
    "5. No fixed directory structure\n",
    "\n",
    "---\n",
    "\n",
    "## Simple Example\n",
    "\n",
    "### Create a table with Liquid Clustering\n",
    "\n",
    "```sql\n",
    "CREATE TABLE customer_txn (\n",
    "  txn_id BIGINT,\n",
    "  customer_id BIGINT,\n",
    "  region STRING,\n",
    "  transaction_date DATE,\n",
    "  amount DOUBLE\n",
    ")\n",
    "USING DELTA\n",
    "CLUSTER BY (customer_id, transaction_date);\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "* `customer_id` and `transaction_date` are **clustering columns**\n",
    "\n",
    "---\n",
    "\n",
    "## How Data Is Stored (Important)\n",
    "\n",
    "Unlike partitioning:\n",
    "\n",
    "```\n",
    "/customer_txn/\n",
    "  ‚îú‚îÄ‚îÄ part-0001.parquet\n",
    "  ‚îú‚îÄ‚îÄ part-0002.parquet\n",
    "  ‚îú‚îÄ‚îÄ part-0003.parquet\n",
    "```\n",
    "\n",
    "There are **no `customer_id=...` folders**.\n",
    "\n",
    "Instead:\n",
    "\n",
    "* Rows with similar `customer_id` and `transaction_date` are colocated **inside files**\n",
    "* File-level min/max stats are optimized\n",
    "\n",
    "---\n",
    "\n",
    "## Query Example\n",
    "\n",
    "```sql\n",
    "SELECT *\n",
    "FROM customer_txn\n",
    "WHERE customer_id = 101\n",
    "  AND transaction_date = '2026-01-15';\n",
    "```\n",
    "\n",
    "### What Delta does internally\n",
    "\n",
    "1. Uses file-level statistics\n",
    "2. Skips files that don‚Äôt match\n",
    "3. Reads only a small subset of files\n",
    "\n",
    "üëâ Similar benefit to Z-ORDER, but **maintained automatically**.\n",
    "\n",
    "---\n",
    "\n",
    "## What Happens on New Writes\n",
    "\n",
    "When new data is inserted:\n",
    "\n",
    "```sql\n",
    "INSERT INTO customer_txn VALUES (...);\n",
    "```\n",
    "\n",
    "Delta:\n",
    "\n",
    "* Writes data already clustered\n",
    "* Avoids layout degradation\n",
    "* No need to rerun Z-ORDER\n",
    "\n",
    "---\n",
    "\n",
    "## Comparison: Partitioning vs Z-ORDER vs Liquid Clustering\n",
    "\n",
    "| Feature                  | Partitioning | Z-ORDER | Liquid Clustering |\n",
    "| ------------------------ | ------------ | ------- | ----------------- |\n",
    "| Folder-based             | Yes          | No      | No                |\n",
    "| Fixed layout             | Yes          | No      | No                |\n",
    "| Manual maintenance       | No           | Yes     | No                |\n",
    "| Handles high cardinality | No           | Yes     | Yes               |\n",
    "| Degrades with new writes | No           | Yes     | No                |\n",
    "| Automatic optimization   | No           | No      | Yes               |\n",
    "\n",
    "---\n",
    "\n",
    "## Liquid Clustering vs Z-ORDER (Key Difference)\n",
    "\n",
    "| Aspect           | Z-ORDER            | Liquid Clustering    |\n",
    "| ---------------- | ------------------ | -------------------- |\n",
    "| Trigger          | Manual OPTIMIZE    | Automatic            |\n",
    "| Rewrite cost     | High               | Incremental          |\n",
    "| Layout stability | Degrades           | Maintained           |\n",
    "| Best for         | Batch optimization | Continuous workloads |\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Liquid Clustering\n",
    "\n",
    "Use Liquid Clustering when:\n",
    "\n",
    "* Table is large\n",
    "* Queries frequently filter on certain columns\n",
    "* Columns have **high cardinality**\n",
    "* Continuous writes / streaming data\n",
    "* You want minimal operational overhead\n",
    "\n",
    "---\n",
    "\n",
    "## When NOT to Use Liquid Clustering\n",
    "\n",
    "* Small tables\n",
    "* Rarely queried tables\n",
    "* Simple partition-based filtering is enough\n",
    "* Very infrequent writes\n",
    "\n",
    "---\n",
    "\n",
    "## How It Works Internally (Simplified)\n",
    "\n",
    "* Delta tracks clustering statistics\n",
    "* Uses adaptive file compaction\n",
    "* Maintains balanced data distribution\n",
    "* Preserves ACID guarantees\n",
    "\n",
    "(No user-visible background jobs required)\n",
    "\n",
    "---\n",
    "\n",
    "## One-Line Mental Model\n",
    "\n",
    "> **Partitioning chooses folders, Z-ORDER rearranges files manually, Liquid Clustering continuously maintains data organization automatically.**\n",
    "\n",
    "---\n",
    "\n",
    "## Interview-Ready Summary\n",
    "\n",
    "> **Liquid Clustering is an automatic, adaptive data layout technique in Delta Lake that continuously clusters data based on query patterns, eliminating the need for fixed partitions or manual Z-ORDER operations.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3aac941-2193-4b14-ba0c-1e4f05542bc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "use lakehousecat.deltadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d29818a-2e14-4d8f-b9cd-2f92e500f067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS sales_orders_liquid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944f4534-126a-4b5a-b54d-061d7a447132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS sales_orders_liquid\n",
    "(\n",
    "  order_id INT,\n",
    "  customer_id INT,\n",
    "  region STRING,\n",
    "  product STRING,\n",
    "  quantity INT,\n",
    "  price DOUBLE,\n",
    "  order_date DATE\n",
    ")\n",
    "USING DELTA\n",
    "CLUSTER BY(customer_id,region);--clustering column can be high or low cardinal, unlike partition which requires only low cardinal columns.\n",
    "--column order used in cluster by is based on the primary filter, ie. whether you first filter based on customer_id or region, accordingly keep the coloumns order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f93763-1130-4ad7-a96b-e8a15c896383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Each insert simulates separate data ingestion.\n",
    "\n",
    "INSERT INTO sales_orders_liquid VALUES\n",
    " (1, 101, 'North', 'Laptop', 2, 65000, '2025-10-01'),\n",
    " (2, 102, 'South', 'Headphones', 5, 2500, '2025-10-01'),\n",
    " (3, 103, 'West', 'Desk Chair', 3, 4500, '2025-10-02');\n",
    "\n",
    "INSERT INTO sales_orders_liquid VALUES\n",
    " (4, 101, 'North', 'Keyboard', 1, 1200, '2025-10-03'),\n",
    " (5, 104, 'East', 'Monitor', 2, 9500, '2025-10-03'),\n",
    " (6, 105, 'South', 'Mouse', 4, 700, '2025-10-03');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5306fb37-b117-4715-844f-609949fe1b57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM sales_orders_liquid where customer_id=102;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01405a5e-8786-4c29-bc05-7b6b80b0e13a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL sales_orders_liquid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c465410-8cd9-494d-9c66-15f2fdb95226",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "UPDATE sales_orders_liquid\n",
    "SET price = price * 1.05\n",
    "WHERE region = 'North';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eeb1c47-6af9-452d-9b2f-a1491e976e0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL sales_orders_liquid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2847ce97-7e60-4fc7-9aee-96b7cb9041c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY sales_orders_liquid;--It proves the optimize and zordering is done naturally (look at the operation column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3ebd901-a9ad-486e-8e74-c984985a5727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DELETE FROM sales_orders_liquid\n",
    "WHERE region = 'East';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "caafb1a4-d28c-497f-a05c-4987738c99c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY sales_orders_liquid;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65d3801b-ce17-430c-8bdb-7373f0734a67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"select * from lakehousecat.deltadb.sales_orders_liquid order by region\").write.clusterBy(\"region\").format(\"csv\").save(\"/Volumes/lakehousecat/deltadb/datalake/cust_txns_clustercsv\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cab3cfac-16c5-4039-9bb3-a0add146bee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5,104,East,Monitor,2,9500.0,2025-10-03<br>\n",
    "1,101,North,Laptop,2,68250.0,2025-10-01<br>\n",
    "4,101,North,Keyboard,1,1260.0,2025-10-03<br>\n",
    "2,102,South,Headphones,5,2500.0,2025-10-01<br>\n",
    "6,105,South,Mouse,4,700.0,2025-10-03<br>\n",
    "3,103,West,Desk Chair,3,4500.0,2025-10-02<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "506a71ae-f08f-4b6d-bc69-e6dc2c7861dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####6. Delta Table ‚Äì CLONE\n",
    "\n",
    "Delta Cloning allows to create a **copy of a Delta table** efficiently:\n",
    "- **Full clone**: independent copy of data and metadata  \n",
    "- **Shallow clone**: metadata-only copy referencing the same underlying data files  \n",
    "\n",
    "**Clone vs CTAS**\n",
    "| Aspect                  | CLONE (Delta Lake)                     | CTAS (Create Table As Select)                |\n",
    "| ----------------------- | -------------------------------------- | -------------------------------------------- |\n",
    "| Type                    | Delta Lake feature                     | Standard SQL feature                         |\n",
    "| Data copy               | Metadata-only (Shallow) or full (Deep) | Full physical data copy                      |\n",
    "| Speed                   | Very fast (especially Shallow Clone)   | Slower for large tables                      |\n",
    "| Storage usage           | Minimal for Shallow Clone              | High (duplicates data)                       |\n",
    "| Time travel & history   | Preserved                              | Not preserved                                |\n",
    "| Schema                  | Exact copy                             | Can be modified                              |\n",
    "| Dependency on source    | Shallow clone depends on source files  | Fully independent                            |\n",
    "| Use case                | Dev/Test copies, backups, experiments  | Aggregations, filtered or transformed tables |\n",
    "| Source table type       | Delta tables only                      | Delta or non-Delta tables                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "114eb659-1ee4-4afd-97db-91251e3ff43e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Delta Table ‚Äì CLONE (Full Clone vs Shallow Clone)\n",
    "\n",
    "Delta Lake provides **CLONE** to create a copy of an existing Delta table efficiently.\n",
    "\n",
    "There are two types of clones:\n",
    "- **Full Clone**\n",
    "- **Shallow Clone**\n",
    "\n",
    "---\n",
    "\n",
    "## What does ‚Äúreferencing the same underlying data files‚Äù mean?\n",
    "\n",
    "**Shallow clone does NOT copy the actual data files (Parquet files).**  \n",
    "It only creates a new Delta table with its own metadata that **points to the same Parquet files** as the source table.\n",
    "\n",
    "---\n",
    "\n",
    "## Delta Table Structure Reminder\n",
    "\n",
    "A Delta table consists of:\n",
    "\n",
    "1. **Data files** ‚Üí Parquet files (`.parquet`)\n",
    "2. **Metadata** ‚Üí Delta transaction log (`_delta_log/`)\n",
    "\n",
    "---\n",
    "\n",
    "## Original Table (Source)\n",
    "\n",
    "/sales_table/<br>\n",
    "‚îú‚îÄ‚îÄ _delta_log/<br>\n",
    "‚îú‚îÄ‚îÄ part-0001.parquet<br>\n",
    "‚îú‚îÄ‚îÄ part-0002.parquet<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Shallow Clone\n",
    "\n",
    "```sql\n",
    "CREATE TABLE sales_clone\n",
    "SHALLOW CLONE sales_table;\n",
    "\n",
    "WHAT HAPPEND:<br>\n",
    "/sales_clone/<br>\n",
    " ‚îú‚îÄ‚îÄ _delta_log/   (new metadata)<br>\n",
    " ‚îú‚îÄ‚îÄ (no parquet files copied)<br>\n",
    "\n",
    " Internally:\n",
    " sales_clone ‚Üí references ‚Üí part-0001.parquet\n",
    "sales_clone ‚Üí references ‚Üí part-0002.parquet\n",
    "\n",
    "Key Point\n",
    "\n",
    "Both tables read the same Parquet files\n",
    "\n",
    "Only metadata is duplicated\n",
    "\n",
    "This is what ‚Äúreferencing the same underlying data files‚Äù means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ad1a640-593f-4fce-b1de-ced97ba3c86d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### CTAS (Create Table as Select)\n",
    "\n",
    "**Full copy** creates an **independent copy**:\n",
    "- Data files are **copied**\n",
    "- No metadata copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12c8dde0-dc92-43f9-8945-47e3fc0f1b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**CREATE TABLE sales_ctas AS<br>\n",
    "SELECT * FROM sales_source<br>**\n",
    "\n",
    "CTAS:\n",
    "\n",
    "- Reads data from sales_source\n",
    "- Writes NEW Parquet files\n",
    "- Creates a brand-new Delta table\n",
    "- Does NOT copy source table metadata\n",
    "\n",
    "What Is ‚ÄúMetadata‚Äù Here?\n",
    "\n",
    "- Metadata includes:\n",
    "- Transaction history (versions)\n",
    "- Commit logs\n",
    "- Operation history\n",
    "- Optimization info (Z-ORDER, clustering)\n",
    "- Table properties\n",
    "\n",
    "üìå CTAS does not copy any of this.\n",
    "\n",
    "Source Table<br>\n",
    "/sales_source/<br>\n",
    " ‚îú‚îÄ‚îÄ _delta_log/<br>\n",
    " ‚îÇ    ‚îú‚îÄ‚îÄ 000000.json<br>\n",
    " ‚îÇ    ‚îú‚îÄ‚îÄ 000001.json<br>\n",
    " ‚îú‚îÄ‚îÄ part-0001.parquet<br>\n",
    " ‚îú‚îÄ‚îÄ part-0002.parquet<br>\n",
    "\n",
    " CTAS Table<br>\n",
    " /sales_ctas/<br>\n",
    " ‚îú‚îÄ‚îÄ _delta_log/<br>\n",
    " ‚îÇ    ‚îú‚îÄ‚îÄ 000000.json   ‚Üê NEW log (fresh history)<br>\n",
    " ‚îú‚îÄ‚îÄ part-0001.parquet  ‚Üê NEW files<br>\n",
    " ‚îú‚îÄ‚îÄ part-0002.parquet  ‚Üê NEW files<br>\n",
    "\n",
    "‚úî Data copied\n",
    "‚úî Metadata rebuilt from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b359bfc6-53ff-41cd-8ae5-e1df76460896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Feature             | CTAS   | Full Clone | Shallow Clone |\n",
    "| ------------------- | ------ | ---------- | ------------- |\n",
    "| Data files copied   | ‚úÖ Yes  | ‚úÖ Yes      | ‚ùå No          |\n",
    "| Metadata copied     | ‚ùå No   | ‚úÖ Yes      | ‚úÖ Yes         |\n",
    "| Transaction history | ‚ùå No   | ‚úÖ Yes      | ‚úÖ Yes         |\n",
    "| Speed               | Slower | Fast       | Very fast     |\n",
    "| VACUUM safe         | ‚úÖ Yes  | ‚úÖ Yes      | ‚ùå No          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6547bdc-f538-4ec4-a121-44660e3a688b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE sales_orders_ctas AS\n",
    "SELECT * FROM sales_orders_liquid;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "340ee233-3b13-40ab-89b1-95edeea8aacb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY sales_orders_ctas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eca604a7-148f-4b48-ad2a-c122abf7c6a2",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769851764728}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESC HISTORY sales_orders_liquid;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "feeaf604-7a47-431e-84cb-fb299b674f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Full Clone\n",
    "\n",
    "**Full clone** creates an **independent copy**:\n",
    "- Data files are **copied**\n",
    "- Medata copied\n",
    "- Uses more storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a78fde0-59b5-4185-ae2e-7732584043da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE sales_orders_sclone \n",
    "CLONE sales_orders_liquid;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b51252a0-8a2f-43b2-b576-57b1a624e43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "describe history sales_orders_liquid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db3bab78-7bd5-49b8-8d91-3f308c76c529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "describe history sales_orders_sclone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "515f567a-d52f-402d-80ea-eb03ed2c98f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Shallow Clone\n",
    "\n",
    "**Shallow clone** creates a **metadata-only copy**:\n",
    "- Shares the same underlying data files\n",
    "- Very fast, uses minimal extra storage\n",
    "- A shallow clone shares data files, but it does NOT share the transaction log\n",
    "- Even if two tables point to the same data files, they are logically independent because they have separate logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9094c13-82d6-433a-8648-9b5ebe23d54e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE sales_orders_l_sclone\n",
    "SHALLOW CLONE sales_orders_sclone;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7100a442-9aca-4e28-82f8-f32ba4bb8ce2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify shallow clone\n",
    "SELECT * FROM sales_orders_l_sclone;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3509e6ee-1de9-48a8-b35a-15f2e8a56259",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY sales_orders_l_sclone;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81d3a153-1343-4df6-be46-cd4746c31c2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "INSERT INTO sales_orders_sclone VALUES\n",
    " (7, 101, 'North', 'Keyboard', 1, 1200, '2025-10-04');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0cd7f4-b5e2-42ed-a185-36f74f3bf06e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "INSERT INTO sales_orders_sclone VALUES\n",
    " (7, 101, 'North', 'Keyboard', 1, 1200, '2025-10-04');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c56bce6-e5e1-4be5-a61c-1532a7bd85e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "UPDATE sales_orders_sclone\n",
    "SET price = 200.1\n",
    "WHERE region = 'South';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f173e819-0b6a-401e-bae8-0debe007ee9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Verify shallow clone\n",
    "SELECT * FROM sales_orders_sclone;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76d077dc-e2ef-46f8-9913-b63d591b28a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Still points the old data files\n",
    "SELECT * FROM sales_orders_l_sclone;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4ac15d2-978d-4f15-beaa-70551c1bd8bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####7. Deletion Vector\n",
    "A Deletion Vector is a metadata structure that marks specific rows as deleted inside a Parquet file, without rewriting the file.<br>\n",
    "Eg. Instead of rewriting whole files, Delta just says: ‚Äúrow 3, row 15, row 102 are deleted‚Äù\n",
    "DV Benifits:\n",
    "- Parquet file count is unchanged\n",
    "- New DV files exist internally\n",
    "\n",
    "If you disable DV:\n",
    "- File rewrite happens\n",
    "- New parquet files created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "305b17ea-284e-4267-920f-fb7b51800456",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE orders_dv AS\n",
    "SELECT\n",
    "  id AS order_id,\n",
    "  CASE WHEN id % 2 = 0 THEN 'APAC' ELSE 'EMEA' END AS region\n",
    "FROM range(0, 20);\n",
    "select * from orders_dv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8111096-3c8c-4e75-b0b4-3edaee07230a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE orders_dv\n",
    "SET TBLPROPERTIES ('delta.enableDeletionVectors' = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6387e5aa-1010-44f7-b7e1-4a5cbff607fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL orders_dv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ff216c4-3606-4b60-81c4-b6f87ad79ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DELETE FROM orders_dv WHERE region = 'APAC';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "492b84f2-69ba-4f44-9792-4d30d1320f06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY orders_dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c549fc-37a7-40b4-8ca2-28a4cbe61083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL orders_dv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4af5943-030f-4e08-9c04-0d022456a7d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "ALTER TABLE orders_dv\n",
    "SET TBLPROPERTIES ('delta.enableDeletionVectors' = false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eb54844-a119-4846-8b8a-8607d53b8079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DELETE FROM orders_dv WHERE order_id = 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c171a0f5-4190-42b2-8c48-d92eb7e0aed2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE DETAIL orders_dv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b498a16-9ceb-461e-a355-157fb2e1828f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "--Check the OperationMetrics\n",
    "DESCRIBE HISTORY orders_dv;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5724402994500063,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "delta_lake_lakehouse_optimizations_2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
